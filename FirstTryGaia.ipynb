{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4119544d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: astroquery in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (0.4.6)\n",
      "Requirement already satisfied: astropy>=4.0 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astroquery) (5.1)\n",
      "Requirement already satisfied: requests>=2.4.3 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astroquery) (2.28.1)\n",
      "Requirement already satisfied: keyring>=4.0 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astroquery) (23.4.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astroquery) (1.23.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.3.2 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astroquery) (4.11.1)\n",
      "Requirement already satisfied: pyvo>=1.1 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astroquery) (1.4.1)\n",
      "Requirement already satisfied: html5lib>=0.999 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astroquery) (1.1)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astropy>=4.0->astroquery) (6.0)\n",
      "Requirement already satisfied: pyerfa>=2.0 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astropy>=4.0->astroquery) (2.0.0)\n",
      "Requirement already satisfied: packaging>=19.0 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from astropy>=4.0->astroquery) (22.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from beautifulsoup4>=4.3.2->astroquery) (2.3.2.post1)\n",
      "Requirement already satisfied: six>=1.9 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from html5lib>=0.999->astroquery) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from html5lib>=0.999->astroquery) (0.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from keyring>=4.0->astroquery) (4.11.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from requests>=2.4.3->astroquery) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from requests>=2.4.3->astroquery) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from requests>=2.4.3->astroquery) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from requests>=2.4.3->astroquery) (2.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from importlib-metadata>=3.6->keyring>=4.0->astroquery) (3.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install astroquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ebe0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # this library is used for working with DataFrames--very useful in astronomy\n",
    "import csv # for working with csv files, like you'd see in Microsoft Excel\n",
    "from matplotlib import pyplot as plt # used for plotting graphs\n",
    "import numpy as np # all sorts of mathematical applications\n",
    "import glob # used for grabbing a bunch of files at once\n",
    "import statistics # the name says it all\n",
    "import scipy # again, all sorts of mathematical applications\n",
    "from mpl_toolkits import mplot3d # used for three-dimensional plots, which we'll revisit at a later time\n",
    "from astroquery import gaia # Gaia!\n",
    "from astroquery.gaia import Gaia\n",
    "import astropy.units as u # very handy for keeping track of units, which are very easy to get mixed up\n",
    "from astropy.units import Quantity\n",
    "from astropy.coordinates.sky_coordinate import SkyCoord # used for interpreting RA and Dec coordinates\n",
    "from astropy import table # sometimes astronomy data downloads in tables, which I find incredibly annoying to work with\n",
    "from astropy.io.votable import parse # used to parse through votable files (again, often seen in astronomy)\n",
    "from scipy.stats import norm # some extra stats stuff I've used for fitting\n",
    "from scipy.stats import powerlaw\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import least_squares\n",
    "import math\n",
    "import astropy.units as u\n",
    "from astropy.coordinates.sky_coordinate import SkyCoord\n",
    "from astroquery.vizier import Vizier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771e46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from seaborn) (3.7.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f65977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeinakellybenton/anaconda3/lib/python3.10/site-packages/astroquery/ipac/irsa/sha/__init__.py:14: UserWarning: Experimental: SHA has not yet been refactored to have its API match the rest of astroquery.\n",
      "  warnings.warn(\"Experimental: SHA has not yet been refactored to have its \"\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns # super cool library that allows us to make contour plots and cool data visualizations\n",
    "from astroquery.ipac.irsa import sha # some extra imports for downloading data\n",
    "from astropy import coordinates as coord\n",
    "from astroquery.ipac.irsa import Irsa\n",
    "import numpy.ma as ma\n",
    "Irsa.ROW_LIMIT = 40000 # limits the number of rows that a query returns so that the query doesn't run forever--just make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03cfa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gaia.ROW_LIMIT = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737ec4f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m coord \u001b[38;5;241m=\u001b[39m SkyCoord(ra \u001b[38;5;241m=\u001b[39m onc_ra, dec \u001b[38;5;241m=\u001b[39m onc_dec, unit\u001b[38;5;241m=\u001b[39m(u\u001b[38;5;241m.\u001b[39mdegree, u\u001b[38;5;241m.\u001b[39mdegree), frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124micrs\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#ICRS = International Celestial Reference System\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#then, you define the size of the area you'd like to look at. Here, we'll look at a cone with a radius of half a degree \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43mGaia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcone_search_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQuantity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.175\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m results \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mget_results()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/astroquery/gaia/core.py:679\u001b[0m, in \u001b[0;36mGaiaClass.cone_search_async\u001b[0;34m(self, coordinate, radius, table_name, ra_column_name, dec_column_name, background, output_file, output_format, verbose, dump_to_file, columns)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcone_search_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, coordinate, radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    641\u001b[0m                       table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    642\u001b[0m                       ra_column_name\u001b[38;5;241m=\u001b[39mMAIN_GAIA_TABLE_RA,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m                       output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvotable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    646\u001b[0m                       verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dump_to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, columns\u001b[38;5;241m=\u001b[39m[]):\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;124;03m\"\"\"Cone search sorted by distance (async)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m    TAP & TAP+\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124;03m    A Job object\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__cone_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mra_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mra_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdec_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                              \u001b[49m\u001b[43masync_job\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbackground\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdump_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdump_to_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/astroquery/gaia/core.py:577\u001b[0m, in \u001b[0;36mGaiaClass.__cone_search\u001b[0;34m(self, coordinate, radius, table_name, ra_column_name, dec_column_name, async_job, background, output_file, output_format, verbose, dump_to_file, columns)\u001b[0m\n\u001b[1;32m    553\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124m        SELECT\u001b[39m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124m          \u001b[39m\u001b[38;5;132;01m{row_limit}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradius\u001b[39m\u001b[38;5;124m'\u001b[39m: radiusDeg,\n\u001b[1;32m    574\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_name\u001b[39m\u001b[38;5;124m'\u001b[39m: table_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAIN_GAIA_TABLE \u001b[38;5;129;01mor\u001b[39;00m conf\u001b[38;5;241m.\u001b[39mMAIN_GAIA_TABLE})\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m async_job:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_job_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdump_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdump_to_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbackground\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlaunch_job(query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[1;32m    585\u001b[0m                            output_file\u001b[38;5;241m=\u001b[39moutput_file,\n\u001b[1;32m    586\u001b[0m                            output_format\u001b[38;5;241m=\u001b[39moutput_format,\n\u001b[1;32m    587\u001b[0m                            verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    588\u001b[0m                            dump_to_file\u001b[38;5;241m=\u001b[39mdump_to_file)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/astroquery/gaia/core.py:903\u001b[0m, in \u001b[0;36mGaiaClass.launch_job_async\u001b[0;34m(self, query, name, output_file, output_format, verbose, dump_to_file, background, upload_resource, upload_table_name, autorun)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlaunch_job_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    863\u001b[0m                      output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvotable\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    864\u001b[0m                      dump_to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, background\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    865\u001b[0m                      upload_resource\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, upload_table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    866\u001b[0m                      autorun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;124;03m\"\"\"Launches an asynchronous job\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \n\u001b[1;32m    869\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;124;03m    A Job object\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTapPlus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_job_async\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdump_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdump_to_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbackground\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mupload_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupload_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mupload_table_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupload_table_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mautorun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautorun\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/astroquery/utils/tap/core.py:459\u001b[0m, in \u001b[0;36mTap.launch_job_async\u001b[0;34m(self, query, name, output_file, output_format, verbose, dump_to_file, background, upload_resource, upload_table_name, autorun)\u001b[0m\n\u001b[1;32m    457\u001b[0m                 job\u001b[38;5;241m.\u001b[39msave_results(verbose)\n\u001b[1;32m    458\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m                 \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m                 log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m job\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/astroquery/utils/tap/model/job.py:246\u001b[0m, in \u001b[0;36mJob.get_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# async: result is in the server once the job is finished\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load_async_job_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/astroquery/utils/tap/model/job.py:367\u001b[0m, in \u001b[0;36mJob.__load_async_job_results\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    366\u001b[0m     outputFormat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 367\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_http_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresultsResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43moutputFormat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_results(results)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/astroquery/utils/tap/xmlparser/utils.py:31\u001b[0m, in \u001b[0;36mread_http_response\u001b[0;34m(response, output_format, correct_units)\u001b[0m\n\u001b[1;32m     28\u001b[0m astropy_format \u001b[38;5;241m=\u001b[39m get_suitable_astropy_format(output_format)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If we want to use astropy.table, we have to read the data\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m data \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     result \u001b[38;5;241m=\u001b[39m APTable\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mBytesIO(gzip\u001b[38;5;241m.\u001b[39mdecompress(data\u001b[38;5;241m.\u001b[39mread())), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mastropy_format)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:591\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m chunk_left \u001b[38;5;241m-\u001b[39m amt\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m value\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_left\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m     amt \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_left\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:630\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "onc_ra = 100.26 #degrees\n",
    "onc_dec = 9.885 #degrees\n",
    "coord = SkyCoord(ra = onc_ra, dec = onc_dec, unit=(u.degree, u.degree), frame='icrs') \n",
    "#ICRS = International Celestial Reference System\n",
    "#then, you define the size of the area you'd like to look at. Here, we'll look at a cone with a radius of half a degree \n",
    "job = Gaia.cone_search_async(coord, radius=u.Quantity(0.175, u.deg))\n",
    "\n",
    "results = job.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0b9ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I like working with pandas DataFrames, so here I am converting the astropy table to a DataFrame\n",
    "dictionary = {}\n",
    "for name in results.colnames:\n",
    "    dictionary[str(name)] = results[str(name)]\n",
    "gaia = pd.DataFrame(data=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf3a96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gaia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0934bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaia['ra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52df11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10)) # making sure it's the same size on both axes so we don't get a weird image\n",
    "plt.scatter(gaia['ra'], gaia['dec'], s=1)\n",
    "plt.show()\n",
    "# here you can see the cluster in the center of the image!\n",
    "\n",
    "\n",
    "\n",
    "#DO ANOTHER REGION OF SOUTH REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5fd33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#histogram\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(gaia['ra'], bins=30)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9061ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(gaia['dec'], bins=30)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07caf14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def distance(parallax):\n",
    "    return (1/(abs(parallax)*10**-3))\n",
    "distances= distance(gaia['parallax'])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(distances, bins=20, range=(0, 1300))\n",
    "\n",
    "plt.savefig('distances.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27e6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7303fc57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df= pd.DataFrame(data=distances)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296962b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def cap_values(value):\n",
    "#     if (value > 600 and value < 900):\n",
    "#         return value\n",
    "    \n",
    "# df= pd.DataFrame(data=distances)\n",
    "# df['parallax']= df['parallax'].apply(cap_values)\n",
    "\n",
    "# #This allows me to still graph it and shows that most starts included in the \n",
    "# #cluster are very far away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425331e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist(df['parallax'], bins=15)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cap_valuess(value):\n",
    "#     if (value > 500 and value < 850):\n",
    "#         return value\n",
    "    \n",
    "# df= pd.DataFrame(data=distances)\n",
    "# df['parallax']= df['parallax'].apply(cap_valuess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist(df['parallax'], bins=15)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3146760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cap_valuesss(value):\n",
    "#     if (value > 200 and value < 850):\n",
    "#         return value\n",
    "    \n",
    "# df= pd.DataFrame(data=distances)\n",
    "# df['parallax']= df['parallax'].apply(cap_valuesss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist(df['parallax'], bins=15)\n",
    "# plt.show\n",
    "\n",
    "#appears to be mostly a chunk between 450 - 650, however sources estimate between majority of stars as 750 or 800 pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cap_value_s(value):\n",
    "#     if (value > 400 and value < 650):\n",
    "#         return value\n",
    "    \n",
    "# df= pd.DataFrame(data=distances)\n",
    "# df['parallax']= df['parallax'].apply(cap_value_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8592f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist(df['parallax'], bins=15)\n",
    "# plt.show\n",
    "\n",
    "#very spread out up when looking closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df.dropna()\n",
    "# print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8de8ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# indices = []\n",
    "# for i in range(0, len(gaia)):\n",
    "#     if np.isnan(gaia['parallax'][i]):\n",
    "#         pass\n",
    "#     else:\n",
    "#         indices.append(i)\n",
    "# indices\n",
    "\n",
    "gaia = pd.DataFrame(data=dictionary)\n",
    "gaia_v2 = gaia.dropna(subset=['parallax'])\n",
    "gaia_v2['distance'] = 1/((10**-3)*abs(gaia_v2['parallax']))\n",
    "gaia_v2 = gaia_v2[(gaia_v2['distance']>=100) & (gaia_v2['distance']<=1000)].reset_index(drop=True)\n",
    "gaia_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = gaia  # change to desired dataframe\n",
    "# twomass_matches = []\n",
    "\n",
    "# for i in range(0, len(df)):\n",
    "#     result = Vizier(columns=[\"**\"], catalog=\"II/246\").query_region(SkyCoord(ra=df['ra'][i], dec=df['dec'][i],\n",
    "#                                                                             unit=(u.deg, u.deg)), radius='5s')\n",
    "#     if len(result) == 0:\n",
    "#         values = [np.nan for i in range(0, 62)]\n",
    "#         twomass_matches.append(values)\n",
    "#     else:\n",
    "#         result = result[0]\n",
    "            \n",
    "#         if len(result) == 1:\n",
    "#             values = [result[colname][0] for colname in result.columns]\n",
    "#             twomass_matches.append(values)\n",
    "#         else:\n",
    "#             diffs = [(((df['ra'][i]-result['RAJ2000'][j])**2)+(df['dec'][i]-result['DEJ2000'][j])**2) for j in range(0, len(result))]\n",
    "#             index = diffs.index(min(diffs))\n",
    "#             values = [result[colname][index] for colname in result.columns]\n",
    "#             twomass_matches.append(values)\n",
    "\n",
    "# # Get column names from the first table in the result\n",
    "# colnames1 = result_table.colnames1 if len(result_table) > 0 else []\n",
    "\n",
    "# # Create a new DataFrame\n",
    "# twomass_df1 = pd.DataFrame(twomass_data1, columns=colnames)\n",
    "\n",
    "# # Concatenate the new DataFrame with the existing one\n",
    "# df_originial = pd.concat([df.reset_index(drop=True), twomass_df1.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# # Save the merged DataFrame to a new CSV file\n",
    "# df_originial.to_csv(\"matching_originial.csv\", index=False)\n",
    "\n",
    "# print(df_originial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77ad8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from filtered distances that i thought the cluster fell into\n",
    "\n",
    "#ASSUMED TO BE NORTH DATA----------\n",
    "\n",
    "df = gaia_v2.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "twomass_data = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    result = Vizier(columns=[\"**\"], catalog=\"II/246\").query_region(\n",
    "        SkyCoord(ra=df['ra'][i], dec=df['dec'][i], unit=(u.deg, u.deg)), radius='20s'\n",
    "    )\n",
    "\n",
    "    if len(result) == 0:\n",
    "        values = [np.nan for _ in range(0, 62)]\n",
    "    else:\n",
    "        result_table = result[0]\n",
    "        if len(result_table) == 1:\n",
    "            values = [result_table[colname][0] for colname in result_table.columns]\n",
    "        else:\n",
    "            diffs = [\n",
    "                (\n",
    "                    ((df['ra'][i] - result_table['RAJ2000'][j]) ** 2)\n",
    "                    + (df['dec'][i] - result_table['DEJ2000'][j]) ** 2\n",
    "                )\n",
    "                for j in range(len(result_table))\n",
    "            ]\n",
    "            index = diffs.index(min(diffs))\n",
    "            values = [result_table[colname][index] for colname in result_table.columns]\n",
    "\n",
    "    twomass_data.append(values)\n",
    "\n",
    "# Get column names from the first table in the result\n",
    "colnames = result_table.colnames if len(result_table) > 0 else []\n",
    "\n",
    "# Create a new DataFrame\n",
    "twomass_df = pd.DataFrame(twomass_data, columns=colnames)\n",
    "\n",
    "# Concatenate the new DataFrame with the existing one\n",
    "merged_df = pd.concat([df.reset_index(drop=True), twomass_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "merged_df.to_excel(\"matched_2mass.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "merged_df = pd.read_excel(\"matched_2mass.xlsx\")\n",
    "\n",
    "# Plot histogram for 'Jmag'\n",
    "plt.hist(merged_df['Jmag'], bins=20, alpha=0.5, label='Jmag')\n",
    "#alpha is transparency or opacity of the plotted data\n",
    "\n",
    "# Plot histogram for 'Kmag'\n",
    "plt.hist(merged_df['Kmag'], bins=20, alpha=0.5, label='Kmag')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('J & K Luminosity Function For Filtered Distances')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('JmagKmag_matched.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = Vizier(columns=[\"**\"], catalog=\"II/246\").query_region(SkyCoord(ra=100.21750927599408, dec=9.875294149694044\n",
    ",\n",
    "                                                                             unit=(u.deg, u.deg)), radius='0.4 deg')\n",
    "dfresult1 = result1[0].to_pandas()\n",
    "\n",
    "print(dfresult1)\n",
    "\n",
    "#this is smaller search of North but with none of naibis points found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame based on 'Jmag' and 'Kmag' columns\n",
    "filtered_result = dfresult1[['Jmag', 'Kmag']].dropna()\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram for 'Jmag'\n",
    "plt.hist(filtered_result['Jmag'], bins=20, alpha=0.5, label='Jmag')\n",
    "#alpha is transparency or opacity of the plotted data\n",
    "\n",
    "# Plot histogram for 'Kmag'\n",
    "plt.hist(filtered_result['Kmag'], bins=20, alpha=0.5, label='Kmag')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('J & K Luminosity Function For Unfiltered Distances')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('JmagKmag_original.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bff343",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmag_range = (filtered_result['Kmag'] >= 5) & (filtered_result['Kmag'] <= 13.5)\n",
    "filtered_Kmag = filtered_result[kmag_range]['Kmag']\n",
    "\n",
    "\n",
    "jmag_range = (filtered_result['Jmag'] >= 5) & (filtered_result['Jmag'] <= 13.5)\n",
    "filtered_Jmag = filtered_result[jmag_range]['Jmag']\n",
    "\n",
    "filtered = filtered_result[kmag_range | jmag_range][['Kmag', 'Jmag']]\n",
    "\n",
    "# Display the filtered data\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f492c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(filtered['Kmag'], bins=40, color='blue', alpha=0.4, label='Filtered Kmag')\n",
    "plt.hist(filtered['Jmag'], bins=40, color='red', alpha=0.4, label='Filtered Jmag')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Filtered Kmag and Jmag')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('filtered_13.5to15.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7511bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmag_range2 = (filtered_result['Kmag'] >= 15) & (filtered_result['Kmag'] <= 16.5)\n",
    "filtered_Kmag2 = filtered_result[kmag_range2]['Kmag']\n",
    "\n",
    "\n",
    "jmag_range2 = (filtered_result['Jmag'] >= 15) & (filtered_result['Jmag'] <= 16.5)\n",
    "filtered_Jmag2 = filtered_result[jmag_range2]['Jmag']\n",
    "\n",
    "filtered2 = filtered_result[kmag_range2 | jmag_range2][['Kmag', 'Jmag']]\n",
    "\n",
    "# Display the filtered data\n",
    "print(filtered2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c19f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(filtered2['Kmag'], bins=40, color='blue', alpha=0.4, label='Filtered2 Kmag')\n",
    "plt.hist(filtered2['Jmag'], bins=40, color='red', alpha=0.4, label='Filtered2 Jmag')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Filtered2 Kmag and Jmag')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('filtered_15to16.5.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a59f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmag_range3 = (filtered_result['Kmag'] >= 16.5) & (filtered_result['Kmag'] <= 19)\n",
    "filtered_Kmag3 = filtered_result[kmag_range3]['Kmag']\n",
    "\n",
    "\n",
    "jmag_range3 = (filtered_result['Jmag'] >= 16.5) & (filtered_result['Jmag'] <= 19)\n",
    "filtered_Jmag3 = filtered_result[jmag_range3]['Jmag']\n",
    "\n",
    "filtered3 = filtered_result[kmag_range3 | jmag_range3][['Kmag', 'Jmag']]\n",
    "\n",
    "# Display the filtered data\n",
    "print(filtered3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b503aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(filtered3['Kmag'], bins=40, color='blue', alpha=0.4, label='Filtered3 Kmag')\n",
    "plt.hist(filtered3['Jmag'], bins=40, color='red', alpha=0.4, label='Filtered3 Jmag')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Filtered3 Kmag and Jmag')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('filtered_16.5to19.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([['Kmag','Jmag']])\n",
    "\n",
    "# Filter the DataFrame based on 'Jmag' and 'Kmag' columns\n",
    "filtered_result_edited = merged_df[['Jmag', 'Kmag']].dropna()\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_result_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b561083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a218ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df[['parallax', 'Jmag', 'Kmag']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance1(parallax):\n",
    "    return (1/(abs(parallax)*10**-3))\n",
    "distances_merged= distance1(merged_df['parallax'])\n",
    "\n",
    "print(distances_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['distances'] = merged_df['parallax'].apply(distance1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(merged_df[['Jmag', 'Kmag', 'distances']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with 1 row and 2 columns\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "\n",
    "# Plot histogram for 'distances'\n",
    "axs[0].hist(merged_df['distances'], bins=25, color='black', alpha=0.7)\n",
    "axs[0].set_title('Distances')\n",
    "axs[0].set_xlabel('Distances')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plot histogram for 'Jmag' and 'Kmag' on the same axes\n",
    "axs[1].hist([merged_df['Jmag'], merged_df['Kmag']], bins=20, alpha=0.7, label=['Jmag', 'Kmag'], color=['lightgreen', 'lightblue'])\n",
    "axs[1].set_title('J & K Mag')\n",
    "axs[1].set_xlabel('Magnitude')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "axs[1].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('histogram_comparison.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram for 'Jmag'\n",
    "plt.hist(filtered_result['Jmag'], bins=20, alpha=0.5, label='Jmag')\n",
    "#alpha is transparency or opacity of the plotted data\n",
    "\n",
    "# Plot histogram for 'Kmag'\n",
    "plt.hist(filtered_result['Kmag'], bins=20, alpha=0.5, label='Kmag')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('J & K Luminosity Function For Unfiltered Distances')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('JmagKmag_original.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d102014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the DataFrame based on magnitude conditions\n",
    "# filtered_df = merged_df[(merged_df['Kmag'] >= 5) & (merged_df['Kmag'] <= 13) & (merged_df['Jmag'] >= 5) & (merged_df['Jmag'] <= 13)]\n",
    "\n",
    "# # Extract distances for the filtered magnitudes\n",
    "# distances_filtered = filtered_df['distances']\n",
    "\n",
    "# # Plot histogram for the filtered distances\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(distances_filtered, bins=20, color='blue', alpha=0.7, label='Distances')\n",
    "# plt.xlabel('Distances')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distances for Magnitudes between 5 and 13')\n",
    "# plt.legend()\n",
    "\n",
    "# # Save the plot as an image\n",
    "# plt.savefig('distances_filtered_histogram.png')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the DataFrame based on magnitude conditions\n",
    "# filtered_df1 = merged_df[(merged_df['Kmag'] >= 13) & (merged_df['Kmag'] <= 15) & (merged_df['Jmag'] >= 13) & (merged_df['Jmag'] <= 15)]\n",
    "\n",
    "# # Extract distances for the filtered magnitudes\n",
    "# distances_filtered1 = filtered_df1['distances']\n",
    "\n",
    "# # Plot histogram for the filtered distances\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(distances_filtered1, bins=20, color='blue', alpha=0.7, label='Distances')\n",
    "# plt.xlabel('Distances')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distances for Magnitudes between 13 and 15')\n",
    "# plt.legend()\n",
    "\n",
    "# # Save the plot as an image\n",
    "# plt.savefig('distances_filtered1_histogram.png')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the DataFrame based on magnitude conditions\n",
    "# filtered_df2 = merged_df[(merged_df['Kmag'] >= 15) & (merged_df['Kmag'] <= 18) & (merged_df['Jmag'] >= 15) & (merged_df['Jmag'] <= 18)]\n",
    "\n",
    "# # Extract distances for the filtered magnitudes\n",
    "# distances_filtered2 = filtered_df2['distances']\n",
    "\n",
    "# # Plot histogram for the filtered distances\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(distances_filtered2, bins=30, color='blue', alpha=0.7, label='Distances')\n",
    "# plt.xlabel('Distances')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distances for Magnitudes between 13 and 15')\n",
    "# plt.legend()\n",
    "\n",
    "# # Save the plot as an image\n",
    "# plt.savefig('distances_filtered2_histogram.png')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f204b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Create a figure with 1 row and 3 columns\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# # Plot the first graph\n",
    "# axs[0].hist(distances_filtered, bins=20, color='blue', alpha=0.7)\n",
    "# axs[0].set_title('Distances for Mag 5 to 13')\n",
    "\n",
    "# # Plot the second graph\n",
    "# axs[1].hist(distances_filtered1, bins=20, color='green', alpha=0.7)\n",
    "# axs[1].set_title('Distances for Mag 13 to 15')\n",
    "\n",
    "# # Plot the third graph\n",
    "# axs[2].hist(distances_filtered2, bins=20, color='red', alpha=0.7)\n",
    "# axs[2].set_title('Distances for Mag 15 to 18')\n",
    "\n",
    "# # Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save the plot as an image\n",
    "# plt.savefig('three_graphs.png')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist(distances_merged, bins=25\n",
    "#          , range=(0, 1000))\n",
    "\n",
    "# plt.show\n",
    "\n",
    "# plt.savefig('distances_merged.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "# #this is from cut data where i filter the parallaxes and ran 2mass matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0802bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist(filtered_result_edited['Jmag'], bins=20)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.hist(filtered_result_edited['Kmag'], bins=20)\n",
    "# plt.show\n",
    "\n",
    "# # x-axis: 'Kmag' values (magnitude in the near-infrared band)\n",
    "# # y-axis: Frequency or count of occurrences in each bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a figure with 1 row and 2 columns\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot histogram for 'distances'\n",
    "axs[0].hist(merged_df['distances'], bins=25, color='black', alpha=0.7)\n",
    "axs[0].set_title('Distances')\n",
    "axs[0].set_xlabel('Distances')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plot histogram for 'Jmag' and 'Kmag' on the same axes with blending\n",
    "axs[1].hist([merged_df['Jmag'], merged_df['Kmag']], bins=20, alpha=0.5, label=['Jmag', 'Kmag'], color=['green', 'blue'])\n",
    "axs[1].set_title('J & K Mag')\n",
    "axs[1].set_xlabel('Magnitude')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "axs[1].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('histogram_comparison.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = merged_df[['Hmag', 'Kmag', 'Jmag']].copy()\n",
    "\n",
    "# Displaying the new DataFrame\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['H_minus_K'] = new_df['Hmag'] - new_df['Kmag']\n",
    "new_df ['J_minus_H'] = new_df['Jmag'] - new_df['Hmag']\n",
    "\n",
    "# Displaying the updated DataFrame\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame based on 'Jmag' and 'Kmag' columns\n",
    "filtered = dfresult1[['Jmag', 'Kmag', 'Hmag']].dropna()\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered['H_minus_K'] = filtered['Hmag'] - filtered['Kmag']\n",
    "filtered['J_minus_H'] = filtered['Jmag'] - filtered['Hmag']\n",
    "print (filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1d76e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_south = [\n",
    "    [1, \"6:41:25.62\", \"9:34:42.97\", 12.98, 0.01, 12.22, 0.01, 11.89, 0.01, 11.47, 0.015, 11.16, 0.03, 10.70, 0.03, 9.98, 0.02, 7.17, 0.07],\n",
    "    [2, \"6:41:23.79\", \"9:33:56.60\", 10.66, 0.01, 10.60, 0.03, 10.54, 0.02, 10.42, 0.007, 10.43, 0.01, 10.42, 0.03, 10.34, 0.02],\n",
    "    [3, \"6:41:17.93\", \"9:33:37.09\", 12.65, 0.01, 11.93, 0.01, 11.78, 0.01, 11.64, 0.038, 11.60, 0.04, 11.54, 0.08, 11.50, 0.06],\n",
    "    [4, \"6:41:21.19\", \"9:32:14.58\", 14.03, 0.01, 13.27, 0.01, 13.09, 0.01, 12.87, 0.013, 12.87, 0.02, 12.63, 0.15, 12.04, 0.02],\n",
    "    [5, \"6:41:24.26\", \"9:31:54.15\", 13.10, 0.01, 12.40, 0.01, 12.31, 0.01, 12.14, 0.029, 12.14, 0.04, 12.04, 0.02, 12.04, 0.08],\n",
    "    [6, \"6:41:18.39\", \"9:31:29.55\", 14.39, 0.01, 13.75, 0.01, 13.53, 0.01, 13.20, 0.033, 13.18, 0.03, 12.97, 0.07, 12.56, 0.04],\n",
    "    [7, \"6:41:19.26\", \"9:30:48.69\", 14.77, 0.01, 14.18, 0.01, 13.87, 0.01, 13.53, 0.046, 13.47, 0.04, 13.68, 0.06],\n",
    "    [8, \"6:41:23.56\", \"9:30:12.45\", 15.64, 0.01, 13.56, 0.01, 12.49, 0.01, 11.79, 0.033, 11.64, 0.02, 11.45, 0.02, 11.34, 0.04],\n",
    "    [9, \"6:41:17.93\", \"9:29:01.07\", 13.39, 0.01, 12.36, 0.01, 11.87, 0.01, 11.16, 0.037, 10.65, 0.04, 10.20, 0.06, 9.36, 0.03, 5.91, 0.04],\n",
    "    [10, \"6:41:18.30\", \"9:28:32.97\", 14.37, 0.01, 13.66, 0.01, 13.43, 0.01, 13.30, 0.051, 13.19, 0.02, 13.29, 0.10],\n",
    "    [11, \"6:41:26.53\", \"9:27:52.53\", 11.45, 0.01, 11.34, 0.02, 11.33, 0.01, 11.31, 0.018, 11.32, 0.01, 11.40, 0.03],\n",
    "    [12, \"6:41:21.92\", \"9:27:39.98\", 14.63, 0.01, 13.72, 0.01, 13.54, 0.01, 13.35, 0.056, 13.19, 0.03, 13.00, 0.06],\n",
    "    [13, \"6:41:24.35\", \"9:27:09.29\", 12.61, 0.01, 11.93, 0.01, 11.76, 0.01, 11.57, 0.026, 11.47, 0.02, 11.38, 0.05],\n",
    "    [14, \"6:41:22.52\", \"9:26:45.81\", 14.97, 0.01, 14.19, 0.01, 13.89, 0.01, 13.48, 0.076, 13.32, 0.05, 13.25, 0.09],\n",
    "    [15, \"6:41:24.43\", \"9:26:21.94\", 15.67, 0.01, 14.56, 0.01, 13.79, 0.01, 13.03, 0.043, 12.86, 0.02, 12.47, 0.05],\n",
    "    [16, \"6:41:24.43\", \"9:26:21.94\", 15.67, 0.01, 14.56, 0.01, 13.79, 0.01, 13.03, 0.043, 12.86, 0.02, 12.47, 0.05],\n",
    "    [17, \"6:41:23.00\", \"9:25:59.47\", 15.56, 0.01, 14.58, 0.01, 13.86, 0.01, 13.20, 0.059, 12.98, 0.03, 12.41, 0.05],\n",
    "    [18, \"6:41:22.76\", \"9:25:35.56\", 15.71, 0.01, 14.80, 0.01, 14.16, 0.01, 13.50, 0.061, 13.27, 0.03, 12.57, 0.06],\n",
    "    [19, \"6:41:24.57\", \"9:25:06.34\", 15.25, 0.01, 14.40, 0.01, 14.06, 0.01, 13.75, 0.046, 13.61, 0.03, 13.49, 0.07],\n",
    "    [20, \"6:41:23.76\", \"9:24:54.66\", 16.15, 0.01, 15.24, 0.01, 14.52, 0.01, 13.92, 0.057, 13.65, 0.03, 12.82, 0.05],\n",
    "    [21, \"6:41:20.27\", \"9:24:43.83\", 14.89, 0.01, 14.03, 0.01, 13.82, 0.01, 13.68, 0.067, 13.37, 0.04, 13.35, 0.08],\n",
    "    [22, \"6:41:21.20\", \"9:24:23.14\", 15.60, 0.01, 14.65, 0.01, 13.86, 0.01, 13.20, 0.065, 12.99, 0.03, 12.43, 0.05],\n",
    "    [23, \"6:41:22.46\", \"9:24:03.66\", 15.27, 0.01, 14.31, 0.01, 13.58, 0.01, 12.97, 0.056, 12.73, 0.03, 12.02, 0.05],\n",
    "    [24, \"6:41:19.76\", \"9:23:51.77\", 15.44, 0.01, 14.42, 0.01, 13.66, 0.01, 13.01, 0.073, 12.77, 0.04, 12.02, 0.06],\n",
    "    [25, \"6:41:23.38\", \"9:23:37.52\", 15.75, 0.01, 14.74, 0.01, 13.99, 0.01, 13.24, 0.056, 13.00, 0.03, 12.41, 0.06],\n",
    "    [26, \"6:41:24.80\", \"9:23:27.34\", 16.20, 0.01, 15.24, 0.01, 14.49, 0.01, 13.84, 0.063, 13.54, 0.03, 12.62, 0.05],\n",
    "    [27, \"6:41:21.94\", \"9:23:06.45\", 14.51, 0.01, 13.80, 0.01, 13.55, 0.01, 13.31, 0.058, 13.20, 0.03, 13.10, 0.07],\n",
    "    [28, \"6:41:23.55\", \"9:22:51.05\", 16.24, 0.01, 15.39, 0.01, 14.62, 0.01, 13.96, 0.057, 13.64, 0.03, 12.79, 0.05],\n",
    "    [29, \"6:41:22.97\", \"9:22:33.06\", 15.73, 0.01, 14.71, 0.01, 14.01, 0.01, 13.29, 0.065, 12.98, 0.03, 12.12, 0.05],\n",
    "    [30, \"6:41:21.55\", \"9:22:20.73\", 14.32, 0.01, 13.40, 0.01, 13.22, 0.01, 13.09, 0.043, 13.09, 0.03, 12.82, 0.07],\n",
    "    [31, \"6:41:20.86\", \"9:22:08.64\", 15.94, 0.01, 14.81, 0.01, 13.94, 0.01, 13.13, 0.074, 12.78, 0.04, 12.01, 0.06],\n",
    "    [32, \"6:41:24.92\", \"9:21:49.57\", 16.07, 0.01, 14.99, 0.01, 14.23, 0.01, 13.47, 0.079, 13.11, 0.05, 12.22, 0.08],\n",
    "    [33, \"6:41:25.30\", \"9:21:37.91\", 15.94, 0.01, 14.94, 0.01, 14.14, 0.01, 13.39, 0.076, 13.00, 0.04, 12.07, 0.07],\n",
    "    [34, \"6:41:20.94\", \"9:21:20.78\", 16.38, 0.01, 15.29, 0.01, 14.43, 0.01, 13.64, 0.087, 13.24, 0.06, 12.35, 0.10],\n",
    "    [35, \"6:41:21.52\", \"9:21:08.79\", 15.37, 0.01, 14.29, 0.01, 13.51, 0.01, 12.76, 0.075, 12.41, 0.04, 11.56, 0.07],\n",
    "    [36, \"6:41:22.80\", \"9:20:58.73\", 15.36, 0.01, 14.33, 0.01, 13.58, 0.01, 12.88, 0.062, 12.53, 0.03, 11.67, 0.06],\n",
    "    [37, \"6:41:20.49\", \"9:20:47.50\", 15.84, 0.01, 14.85, 0.01, 14.06, 0.01, 13.36, 0.066, 13.04, 0.03, 12.18, 0.06],\n",
    "    [38, \"6:41:24.34\", \"9:20:35.92\", 16.42, 0.01, 15.40, 0.01, 14.52, 0.01, 13.68, 0.075, 13.27, 0.05, 12.38, 0.08],\n",
    "    [39, \"6:41:21.86\", \"9:20:26.03\", 16.03, 0.01, 15.06, 0.01, 14.27, 0.01, 13.47, 0.078, 13.09, 0.05, 12.25, 0.08],\n",
    "    [40, \"6:41:23.46\", \"9:20:16.17\", 16.17, 0.01, 15.15, 0.01, 14.35, 0.01, 13.58, 0.073, 13.17, 0.05, 12.34, 0.08],\n",
    "    [41, \"6:41:24.72\", \"9:20:05.38\", 15.68, 0.01, 14.61, 0.01, 13.77, 0.01, 12.92, 0.068, 12.55, 0.03, 11.67, 0.06],\n",
    "    [42, \"6:41:20.53\", \"9:19:52.62\", 14.73, 0.01, 13.69, 0.01, 12.96, 0.01, 12.35, 0.055, 11.97, 0.03, 11.11, 0.06],\n",
    "    [43, \"6:41:24.16\", \"9:19:41.93\", 15.20, 0.01, 14.23, 0.01, 13.50, 0.01, 12.87, 0.065, 12.52, 0.03, 11.63, 0.05],\n",
    "    [44, \"6:41:20.94\", \"9:19:32.94\", 15.67, 0.01, 14.66, 0.01, 13.84, 0.01, 13.02, 0.071, 12.68, 0.04, 11.83, 0.07],\n",
    "    [45, \"6:41:24.17\", \"9:19:23.56\", 15.82, 0.01, 14.86, 0.01, 14.09, 0.01, 13.30, 0.083, 12.93, 0.05, 12.03, 0.08],\n",
    "    [46, \"6:41:20.78\", \"9:19:13.50\", 15.57, 0.01, 14.50, 0.01, 13.72, 0.01, 13.00, 0.065, 12.66, 0.03, 11.79, 0.06],\n",
    "    [47, \"6:41:23.72\", \"9:19:02.15\", 15.59, 0.01, 14.63, 0.01, 13.84, 0.01, 13.11, 0.077, 12.74, 0.04, 11.86, 0.07],\n",
    "    [48, \"6:41:21.47\", \"9:18:50.36\", 15.73, 0.01, 14.80, 0.01, 14.06, 0.01, 13.34, 0.079, 12.97, 0.05, 12.07, 0.08],\n",
    "    [49, \"6:41:23.54\", \"9:18:39.61\", 15.95, 0.01, 15.01, 0.01, 14.26, 0.01, 13.56, 0.077, 13.17, 0.05, 12.30, 0.08],\n",
    "    [50, \"6:41:20.21\", \"9:18:27.48\", 15.45, 0.01, 14.45, 0.01, 13.65, 0.01, 12.90, 0.075, 12.55, 0.03, 11.70, 0.06],\n",
    "    [51, \"6:41:24.42\", \"9:18:16.16\", 15.70, 0.01, 14.76, 0.01, 13.97, 0.01, 13.25, 0.083, 12.86, 0.05, 11.94, 0.08],\n",
    "    [52, \"6:41:21.21\", \"9:18:04.63\", 15.61, 0.01, 14.68, 0.01, 13.90, 0.01, 13.18, 0.073, 12.84, 0.05, 11.94, 0.08],\n",
    "    [53, \"6:41:23.63\", \"9:17:55.92\", 15.77, 0.01, 14.84, 0.01, 14.08, 0.01, 13.31, 0.078, 12.96, 0.05, 12.07, 0.08],\n",
    "    [54, \"6:41:21.76\", \"9:17:45.70\", 15.73, 0.01, 14.79, 0.01, 14.03, 0.01, 13.25, 0.079, 12.86, 0.05, 11.94, 0.08]\n",
    "]\n",
    "\n",
    "columns = [\n",
    "    \"Spectroscopic Sample No.\", \"R.A. (J2000)\", \"Decl. (J2000)\",\"J\", \"eJ\", \"H\", \"eH\", \"K\", \"eK\",\n",
    "    \"[3.6]\", \"e[3.6]\", \"[4.5]\", \"e[4.5]\", \"[5.8]\", \"e[5.8]\", \"[8]\", \"e[8]\", \"[24]\", \"e[24]\"\n",
    "]\n",
    "df_south = pd.DataFrame(data_south, columns=columns)\n",
    "\n",
    "df_south.to_excel(\"df_south_data.xlsx\", index=False)\n",
    "\n",
    "print(df_south)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f54975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def open_and_convert_to_degrees(file_path):\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Convert \"R.A. (J2000)\" from hours, minutes, seconds to degrees\n",
    "    ra_degrees = []\n",
    "    for ra_str in df[\"R.A. (J2000)\"]:\n",
    "        ra_parts = ra_str.split(\":\")\n",
    "        ra_deg = (float(ra_parts[0]) + float(ra_parts[1])/60 + float(ra_parts[2])/3600) * 15\n",
    "        ra_degrees.append(ra_deg)\n",
    "    df[\"R.A. (J2000)\"] = ra_degrees\n",
    "    \n",
    "    # Convert \"Decl. (J2000)\" from degrees, arcminutes, arcseconds to degrees\n",
    "    dec_degrees = []\n",
    "    for dec_str in df[\"Decl. (J2000)\"]:\n",
    "        dec_parts = dec_str.split(\":\")\n",
    "        sign = -1 if dec_parts[0].startswith(\"-\") else 1\n",
    "        dec_deg = sign * (abs(float(dec_parts[0])) + float(dec_parts[1])/60 + float(dec_parts[2])/3600)\n",
    "        dec_degrees.append(dec_deg)\n",
    "    df[\"Decl. (J2000)\"] = dec_degrees\n",
    "    \n",
    "    return df\n",
    "\n",
    "file_path = \"df_south_data.xlsx\"\n",
    "df_south_degrees = open_and_convert_to_degrees(file_path)\n",
    "print(df_south_degrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bcc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"df_south_data.xlsx\"\n",
    "df_south_degrees = open_and_convert_to_degrees(file_path)\n",
    "\n",
    "# Calculate most frequently repeated RA and DEC\n",
    "most_freq_ra = df_south_degrees[\"R.A. (J2000)\"].mode().values[0]\n",
    "avg_ra = df_south_degrees[\"R.A. (J2000)\"].mean()\n",
    "\n",
    "most_freq_dec = df_south_degrees[\"Decl. (J2000)\"].mode().values[0]\n",
    "avg_dec = df_south_degrees[\"Decl. (J2000)\"].mean()\n",
    "\n",
    "print(\"Most frequently repeated RA:\", most_freq_ra)\n",
    "print(\"Average RA:\", avg_ra)\n",
    "\n",
    "print(\"Most frequently repeated DEC:\", most_freq_dec)\n",
    "print(\"Average DEC:\", avg_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "onc_ra1 = 100.32470833333335  # degrees\n",
    "onc_dec1 = 9.439427777777778  # degrees\n",
    "coord1 = SkyCoord(ra=onc_ra1, dec=onc_dec1, unit=(u.degree, u.degree), frame='icrs')\n",
    "job1 = Gaia.cone_search_async(coord1, radius=u.Quantity(0.15, u.deg))\n",
    "\n",
    "results1 = job1.get_results()  # Corrected to job1\n",
    "gaia1 = results1.to_pandas()  # Convert results to pandas DataFrame\n",
    "\n",
    "#gaia1 is the south region survey\n",
    "\n",
    "print(gaia1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89846f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gaia1.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "twomass1_data = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    result = Vizier(columns=[\"**\"], catalog=\"II/246\").query_region(\n",
    "        SkyCoord(ra=df['ra'][i], dec=df['dec'][i], unit=(u.deg, u.deg)), radius='20s'\n",
    "    )\n",
    "\n",
    "    if len(result) == 0:\n",
    "        values = [np.nan for _ in range(0, 62)]\n",
    "    else:\n",
    "        result_table = result[0]\n",
    "        if len(result_table) == 1:\n",
    "            values = [result_table[colname][0] for colname in result_table.columns]\n",
    "        else:\n",
    "            diffs = [\n",
    "                (\n",
    "                    ((df['ra'][i] - result_table['RAJ2000'][j]) ** 2)\n",
    "                    + (df['dec'][i] - result_table['DEJ2000'][j]) ** 2\n",
    "                )\n",
    "                for j in range(len(result_table))\n",
    "            ]\n",
    "            index = diffs.index(min(diffs))\n",
    "            values = [result_table[colname][index] for colname in result_table.columns]\n",
    "\n",
    "    twomass1_data.append(values)\n",
    "\n",
    "# Get column names from the first table in the result\n",
    "colnames = result_table.colnames if len(result_table) > 0 else []\n",
    "\n",
    "# Create a new DataFrame\n",
    "twomass1_df = pd.DataFrame(twomass1_data, columns=colnames)\n",
    "\n",
    "# Concatenate the new DataFrame with the existing one\n",
    "SOUTH_df = pd.concat([df.reset_index(drop=True), twomass1_df.reset_index(drop=True)], axis=1)\n",
    "SOUTH_df.to_excel(\"matched_2mass_SOUTH.xlsx\", index=False)\n",
    "\n",
    "#COMBINED 2mass data of South region!!! BIG\n",
    "\n",
    "print(SOUTH_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = Vizier(columns=[\"**\"], catalog=\"II/246\").query_region(\n",
    "    SkyCoord(ra=100.32470833333335, dec=9.439427777777778, unit=(u.deg, u.deg)), \n",
    "    radius='0.4 deg'\n",
    ")\n",
    "\n",
    "# Converting the result to a pandas DataFrame\n",
    "SOUTH2mass = result2[0].to_pandas()\n",
    "\n",
    "# Printing the DataFrame\n",
    "print(SOUTH2mass)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#THIS IS 2MASS FOR SOUTH REGION SMALLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance2(parallax):\n",
    "     return (1/(abs(parallax)*10**-3))\n",
    "distances2= distance2(gaia1['parallax'])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(distances2, bins=20, range=(0, 1300))\n",
    "\n",
    "plt.savefig('distances2.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the data\n",
    "dataC1 = {\n",
    "    'ID': ['m4_7', 'm4_15', 'm4_12', 'm2_26', 'm2_4', 'm4_13', 'm1_26', 'm1_21', 'm2_16', 'm4_21',\n",
    "           'm2_15', 'm2_27', 'm1_6', 'm2_25', 'm1_11', 'm1_24', 'm1_22', 'm2_7', 'm2_8', 'm2_3',\n",
    "           'm2_5', 'm1_8', 'm2_10', 'm1_16', 'm4_3', 'm1_19', 'm1_10', 'm4_4', 'm1_23', 'm1_18',\n",
    "           'm4_16', 'm1_14', 'm2_13', 'm2_12', 'm1_13', 'm2_9', 'm1_17', 'm2_18', 's1_22', 's1_6',\n",
    "           's1_20', 's1_2', 's1_27', 's1_23', 's1_13', 's1_26', 's1_15', 's1_8', 's1_11', 's1_17',\n",
    "           's1_14', 's1_18', 's1_24', 's1_10', 's1_16', 's1_5', 's1_9', 'A1', 'A4', 'A5', 'A6', 'A7',\n",
    "           'A9', 'A10', 'A11', 'A15', 'A17', 'A18', 'A21', 'A27', 'A32', 'A33', 'A38', 'A39', 'A44',\n",
    "           'A46', 'A47', 'A50', 'A54', 'A55', 'A56', 'A58', 'A59', 'A61', 'A63', 'A66', 'A67', 'A68',\n",
    "           'A70', 'A71', 'A72', 'A75', 'A76', 'A78', 'A82', 'A84', 'A87', 'A89', 'A92', 'A95', 'A97',\n",
    "           'A99', 'A100', 'A101', 'A103', 'A104'],\n",
    "    'RA': ['6:40:41.14', '6:40:41.31', '6:40:41.32', '6:40:43.86', '6:40:43.93', '6:40:44.12', '6:40:44.58',\n",
    "           '6:40:44.81', '6:40:45.07', '6:40:46.10', '6:40:46.22', '6:40:46.68', '6:40:46.73', '6:40:46.96',\n",
    "           '6:40:46.96', '6:40:47.36', '6:40:47.50', '6:40:47.81', '6:40:48.10', '6:40:48.11', '6:40:49.27',\n",
    "           '6:40:49.55', '6:40:49.75', '6:40:49.99', '6:40:50.59', '6:40:50.77', '6:40:50.81', '6:40:50.94',\n",
    "           '6:40:51.04', '6:40:51.14', '6:40:51.34', '6:40:51.56', '6:40:52.09', '6:40:52.21', '6:40:52.55',\n",
    "           '6:40:53.01', '6:40:53.15', '6:40:53.95', '6:40:59.87', '6:41:00.44', '6:41:01.95', '6:41:02.84',\n",
    "           '6:41:02.96', '6:41:04.04', '6:41:04.18', '6:41:04.34', '6:41:04.44', '6:41:04.47', '6:41:04.83',\n",
    "           '6:41:04.98', '6:41:05.10', '6:41:05.11', '6:41:05.14', '6:41:05.81', '6:41:08.16', '6:41:08.17',\n",
    "           '6:41:08.85', '6:40:41.03', '6:40:41.362', '6:40:41.42', '6:40:41.80', '6:40:41.85', '6:40:43.22',\n",
    "           '6:40:43.2265', '6:40:43.35', '6:40:44.59', '6:40:44.64', '6:40:44.80', '6:40:46.083', '6:40:47.21',\n",
    "           '6:40:48.38', '6:40:48.89', '6:40:50.08', '6:40:50.33', '6:40:50.86', '6:40:51.185', '6:40:52.01',\n",
    "           '6:40:52.68', '6:40:54.20', '6:40:54.26', '6:40:55.18', '6:40:55.74', '6:40:55.87', '6:40:56.51',\n",
    "           '6:40:56.95', '6:40:58.94', '6:40:59.323', '6:40:59.343', '6:40:59.91', '6:41:00.03', '6:41:00.503',\n",
    "           '6:41:01.69', '6:41:01.874', '6:41:02.205', '6:41:04.18', '6:41:04.41', '6:41:04.57', '6:41:05.10',\n",
    "           '6:41:05.68', '6:41:06.42', '6:41:08.86', '6:41:10.38', '6:41:10.79','6:41:12.82', '6:41:15.42', '6:41:17.10'],\n",
    "\n",
    "           \n",
    "    'DEC':['9:52:56.60', '9:49:19.24', '9:51:02.39', '9:48:30.51', '9:55:16.94', '9:49:57.44', '9:48:12.55',\n",
    "        '9:49:47.72', '9:51:27.65', '9:47:14.38', '9:51:40.09', '9:48:12.60', '9:54:24.79', '9:48:48.02',\n",
    "        '9:52:40.51', '9:48:49.38', '9:49:28.88', '9:53:55.42', '9:53:39.43', '9:55:36.97', '9:54:43.15',\n",
    "        '9:53:23.07', '9:52:58.63', '9:51:12.66', '9:54:57.40', '9:50:25.25', '9:52:57.61', '9:54:32.91',\n",
    "        '9:49:06.02', '9:50:37.87', '9:49:05.78', '9:51:49.08', '9:52:13.80', '9:52:31.22', '9:52:05.97',\n",
    "        '9:53:23.79', '9:50:50.13', '9:50:58.01', '9:49:32.82', '9:54:03.61', '9:50:03.72', '9:55:22.21',\n",
    "        '9:47:54.31', '9:49:08.73', '9:52:01.95', '9:48:22.01', '9:51:26.07', '9:53:18.41', '9:52:25.40',\n",
    "        '9:50:46.06', '9:51:44.51', '9:50:30.22', '9:48:55.46', '9:52:47.85', '9:51:09.85', '9:54:15.66',\n",
    "        '9:53:01.13', '9:47:57.7', '9:54:13.90', '9:48:09.6', '9:49:52.3', '9:51:44.5', '9:47:07.3',\n",
    "        '9:46:01.707', '9:50:59.6', '9:48:12.6', '9:48:02.1', '9:49:47.8', '9:49:17.33', '9:53:09.2',\n",
    "        '9:48:38.6', '9:51:44.4', '9:52:27.5', '9:54:15.9', '9:55:53.1', '9:44:46.12', '9:45:04.8',\n",
    "        '9:44:21.0', '9:55:52.0', '9:49:20.4', '9:50:49.8', '9:46:45.7', '9:51:30.5', '9:54:10.4',\n",
    "        '9:48:40.7', '9:54:00.8', '9:46:16.62', '9:55:20.18', '9:47:04.4', '9:52:17.9', '9:45:03.14',\n",
    "        '9:48:22.2', '9:52:47.96', '9:51:51.95', '9:52:02.0', '9:51:50.1', '9:54:43.9', '9:48:48.0',\n",
    "        '9:54:18.7', '9:54:10.7', '9:46:01.0', '9:53:01.9', '9:46:41.2', '9:52:43.4', '9:46:39.68', '9:52:40.5']\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "C1df = pd.DataFrame(dataC1)\n",
    "\n",
    "# Display DataFrame\n",
    "print(C1df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_coordinates(df):\n",
    "    # Convert \"RA\" from hours, minutes, seconds to degrees\n",
    "    ra_degrees = []\n",
    "    for ra_str in df[\"RA\"]:\n",
    "        ra_parts = ra_str.split(\":\")\n",
    "        ra_deg = (float(ra_parts[0]) + float(ra_parts[1])/60 + float(ra_parts[2])/3600) * 15\n",
    "        ra_degrees.append(ra_deg)\n",
    "    df[\"RA\"] = ra_degrees\n",
    "    \n",
    "    # Convert \"DEC\" from degrees, arcminutes, arcseconds to degrees\n",
    "    dec_degrees = []\n",
    "    for dec_str in df[\"DEC\"]:\n",
    "        dec_parts = dec_str.split(\":\")\n",
    "        sign = -1 if dec_parts[0].startswith(\"-\") else 1\n",
    "        dec_deg = sign * (abs(float(dec_parts[0])) + float(dec_parts[1])/60 + float(dec_parts[2])/3600)\n",
    "        dec_degrees.append(dec_deg)\n",
    "    df[\"DEC\"] = dec_degrees\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Assuming C1df is your DataFrame with \"RA\" and \"DEC\" columns\n",
    "C1df = pd.DataFrame(dataC1)\n",
    "C1df = convert_coordinates(C1df)\n",
    "print(C1df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a35a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#A REPEAT OF SOUTH DATA FROM NAIBI \n",
    "\n",
    "# dataC2 = {\n",
    "#     'ID': [6.690450, 6.6899417, 6.6883139, 6.6892194, 6.6900722, 6.6884417, 6.6886833, 6.6898778,\n",
    "#             6.6883139, 6.6884167, 6.6845333, 6.6840528, 6.683725, 6.6844611, 6.6820222, 6.6830694,\n",
    "#             6.6842917, 6.6826833, 6.6843056, 6.6827167, 6.6843361, 6.6820306, 6.6823583, 6.6850889,\n",
    "#             6.683475, 6.6841917, 6.6830306, 6.6844444, 6.6872917, 6.6864806, 6.6867083, 6.6837028,\n",
    "#             6.6857056, 6.6831556, 6.6850639, 6.6842194, 6.6831194, 6.6849306, 6.6858583, 6.6850722,\n",
    "#             6.6855694, 6.6853222, 6.6851194, 6.6853861, 6.685400, 6.6864083, 6.6873528, 6.6880722,\n",
    "#             6.6874556, 6.6870278, 6.6875833, 6.6856, 6.6858472, 6.6805556, 6.6809444, 6.681, 6.6811389,\n",
    "#             6.6815556, 6.6816111, 6.682, 6.6823333, 6.6825, 6.6829194, 6.6829722, 6.683, 6.6831944,\n",
    "#             6.6831944, 6.6833333, 6.6836111, 6.6837667, 6.6840278, 6.6842778, 6.6843611, 6.6843611,\n",
    "#             6.6844722, 6.6844778, 6.6846111, 6.68475, 6.6848333, 6.6848611, 6.6849722, 6.6851111,\n",
    "#             6.6851944, 6.685225, 6.68525, 6.6853333, 6.6853611, 6.6853889, 6.6855, 6.6859722, 6.6860556,\n",
    "#             6.6861389, 6.6861944, 6.6863889, 6.6866111, 6.6869278, 6.6869722, 6.687, 6.6870278,\n",
    "#             6.68725, 6.6873333, 6.6874167, 6.6875278, 6.6876944, 6.6877, 6.6879722, 6.688, 6.68825,\n",
    "#             6.6884167, 6.6885833, 6.6887222, 6.6887778, 6.6888611, 6.6891667, 6.6896667, 6.6897778,\n",
    "#             6.6908333, 6.6908611, 6.6908889, 6.6921389],\n",
    "#     'RA': [9.5786028, 9.5657222, 9.5603028, 9.5373833, 9.5317083, 9.524875, 9.513525, 9.5034583,\n",
    "#             9.4836306, 9.475825, 9.5966111, 9.5869806, 9.5689472, 9.563525, 9.5569194,            9.5505056, 9.5365806, 9.5305861, 9.5217722, 9.5139583, 9.5080278, 9.5021583, 9.4982556,\n",
    "#             9.491875, 9.4877333, 9.484550, 9.4813056, 9.4734278, 9.5559389, 9.5141028, 9.4978222,\n",
    "#             9.5813056, 9.5703528, 9.5593, 9.5524583, 9.5486333, 9.530625, 9.5170167, 9.502525,\n",
    "#             9.4945472, 9.4655083, 9.4581528, 9.4496556, 9.5891111, 9.5760083, 9.5701194, 9.55595,\n",
    "#             9.547875, 9.5433028, 9.5306306, 9.5212111, 9.5112, 9.4853389, 9.5111111, 9.5036111,\n",
    "#             9.4791667, 9.4872222, 9.5569444, 9.5108333, 9.5552778, 9.5980556, 9.5502778, 9.5588417,\n",
    "#             9.6036111, 9.5158333, 9.4975, 9.5863889, 9.4805556, 9.5455556, 9.4703028, 9.5822222,\n",
    "#             9.5013889, 9.4611111, 9.4722222, 9.5891667, 9.55055, 9.4358333, 9.55, 9.5536111,\n",
    "#             9.5277778, 9.455, 9.4775, 9.5794444, 9.4590528, 9.49, 9.4633333, 9.4319444, 9.5197222,\n",
    "#             9.4705556, 9.5902778, 9.4533333, 9.5244444, 9.5569444, 9.5986111, 9.4419444, 9.5972889,\n",
    "#             9.5186111, 9.4363889, 9.4688889, 9.4447222, 9.4494444, 9.5705556, 9.4455556, 9.4380556,\n",
    "#             9.4426, 9.4977778, 9.4583333, 9.4905556, 9.5647222, 9.4544444, 9.5080556, 9.5288889,\n",
    "#             9.4513889, 9.56, 9.4941667, 9.51, 9.5036111, 9.585, 9.5352778, 9.5316667],\n",
    "#     'DEC': [16.05, 11.29, 15.36, 17.77, 15.42, 18.43, 19.71, 99, 18.55, 18.24, 18.37, 15.35, 14.63,\n",
    "#             99, 20.05, 99, 19.52, 18.96, 12.72, 16.46, 17.79, 20.56, 18.49, 17.67, 14.71, 18.53,\n",
    "#             16.8, 19.23, 99, 20.62, 17.91, 16.46, 14.93, 18.64, 20.59, 99, 15.41, 16.41, 9,\n",
    "#             99, 13.56, 99, 99, 99, 19.85, 99, 15.45, 18.07, 16.99, 17.71, 9.76, 15.61, 22.35, 19.02,\n",
    "#             18.28, 16.05, 19.06, 14.63, 11.61, 19.35, 16.78, 20.34, 10.2, 17.06, 14.04, 16.86, 15.36,\n",
    "#             15.76, 13.93, 10.69, 14.31, 16.99, 16.07, 17.56, 16.6, 10.03, 18.45, 17.57, 15.19, 17.57,\n",
    "#             16.3, 17.32, 16.14, 13.56, 16.54, 14.91, 15.15, 17.84, 16.31, 15.78, 14.5, 17.86, 17.49,\n",
    "#             17.44, 15.18, 9.16, 19.29, 14.31, 16.77, 16.48, 17.24, 17.42, 16.74, 13.67, 16.68, 15.81,\n",
    "#             15.13, 15.74, 14.97, 17.37, 13.86, 14.42, 17.96, 15.1, 15.81, 17.53, 17.47, 14.28, 18.62,\n",
    "#             17.38]\n",
    "# }\n",
    "\n",
    "# dfc2 = pd.DataFrame(dataC2)\n",
    "# print(dfc2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))  # Corrected parentheses around figsize\n",
    "\n",
    "plt.scatter(gaia['ra'], gaia['dec'], s=1, label='gaia', color='black') \n",
    "plt.scatter(C1df['RA'], C1df['DEC'], s=1, color='red', label='')\n",
    "plt.scatter(df_south_degrees['R.A. (J2000)'], df_south_degrees['Decl. (J2000)'], s=1, color='green', label='')\n",
    "plt.scatter(gaia1['ra'], gaia1['dec'], s=1, label='gaia1', color='blue')\n",
    "\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('Dec')\n",
    "\n",
    "fig.savefig('Clusters_with_gaia.png')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame with the same columns as C1df\n",
    "filtered_C1df = pd.DataFrame(columns=C1df.columns.tolist() + ['parallax'])\n",
    "\n",
    "# Define the tolerance\n",
    "tolerance = 0.0003\n",
    "\n",
    "\n",
    "# Iterate over each row in C1df\n",
    "for index, row in C1df.iterrows():\n",
    "    # Extract RA and DEC from the current row\n",
    "    ra_c1 = row['RA']\n",
    "    dec_c1 = row['DEC']\n",
    "    \n",
    "    # Iterate over each row in gaia to compare with current C1df row\n",
    "    for _, gaia_row in gaia.iterrows():\n",
    "        ra_gaia = gaia_row['ra']\n",
    "        dec_gaia = gaia_row['dec']\n",
    "        parallax_gaia = gaia_row['parallax']  # Extract parallax from gaia\n",
    "        \n",
    "        # Check if the difference between RA and DEC values is within tolerance\n",
    "        ra_diff = abs(ra_c1 - ra_gaia)\n",
    "        dec_diff = abs(dec_c1 - dec_gaia)\n",
    "        \n",
    "        if ra_diff <= tolerance and dec_diff <= tolerance:\n",
    "            # If within tolerance, add the current C1df row to filtered_C1df\n",
    "            filtered_row = row.copy()  # Copy the current C1df row\n",
    "            filtered_row['parallax'] = parallax_gaia  # Add parallax to the copied row\n",
    "            filtered_C1df = pd.concat([filtered_C1df, filtered_row.to_frame().T], ignore_index=True)\n",
    "            # Break the loop as we found a match for the current C1df row\n",
    "            break\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_C1df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ec3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_C1df.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "C1df_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    result = Vizier(columns=[\"**\"], catalog=\"II/246\").query_region(\n",
    "        SkyCoord(ra=row['RA'], dec=row['DEC'], unit=(u.deg, u.deg)), radius='20s'\n",
    "    )\n",
    "\n",
    "    if len(result) == 0:\n",
    "        values = [np.nan for _ in range(0, 62)]\n",
    "    else:\n",
    "        result_table = result[0]\n",
    "        if len(result_table) == 1:\n",
    "            values = [result_table[colname][0] for colname in result_table.columns]\n",
    "        else:\n",
    "            diffs = [\n",
    "                (\n",
    "                    ((row['RA'] - result_table['RAJ2000'][j]) ** 2)\n",
    "                    + (row['DEC'] - result_table['DEJ2000'][j]) ** 2\n",
    "                )\n",
    "                for j in range(len(result_table))\n",
    "            ]\n",
    "            index = diffs.index(min(diffs))\n",
    "            values = [result_table[colname][index] for colname in result_table.columns]\n",
    "\n",
    "    C1df_data.append(values)\n",
    "\n",
    "# Get column names from the first table in the result\n",
    "colnames = result_table.colnames if len(result_table) > 0 else []\n",
    "\n",
    "# Create a new DataFrame\n",
    "C1df_df = pd.DataFrame(C1df_data, columns=colnames)\n",
    "\n",
    "# Concatenate the new DataFrame with the existing one\n",
    "C1df_2mass = pd.concat([df.reset_index(drop=True), C1df_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save the new DataFrame to an Excel file\n",
    "C1df_2mass.to_excel(\"C1df_2mass.xlsx\", index=False)\n",
    "\n",
    "print(C1df_2mass)\n",
    "\n",
    "\n",
    "#BIG GAIA SURVEY OF NORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004bcd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1df_2mass = pd.read_excel(\"C1df_2mass.xlsx\")\n",
    "\n",
    "# Assuming the correct column names are 'Jmag', 'Hmag', and 'Kmag'\n",
    "JHK_df = C1df_2mass[['Jmag', 'Hmag', 'Kmag']]\n",
    "\n",
    "# Compute H-K and J-H\n",
    "JHK_df['H_K'] = JHK_df['Hmag'] - JHK_df['Kmag']\n",
    "JHK_df['J_H'] = JHK_df['Jmag'] - JHK_df['Hmag']\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(JHK_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b318b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"df_south_data.xlsx\"\n",
    "\n",
    "# Call the function to read the Excel file and convert coordinates\n",
    "df_south_degrees = open_and_convert_to_degrees(file_path)\n",
    "\n",
    "# Create an empty DataFrame with the desired columns\n",
    "Southdf = pd.DataFrame(columns=['R.A. (J2000)', 'Decl. (J2000)', 'parallax'])\n",
    "\n",
    "# Define the tolerance\n",
    "tolerance = 0.003\n",
    "\n",
    "# Iterate over each row in df_south_degrees\n",
    "for index, row in df_south_degrees.iterrows():\n",
    "    # Extract RA and DEC from the current row\n",
    "    ra_south = row['R.A. (J2000)']\n",
    "    dec_south = row['Decl. (J2000)']\n",
    "    \n",
    "    # Initialize parallax value\n",
    "    parallax_value = None\n",
    "    \n",
    "    # Iterate over each row in gaia to compare with current df_south_degrees row\n",
    "    for _, gaia1_row in gaia1.iterrows():\n",
    "        ra_gaia1 = gaia1_row['ra']\n",
    "        dec_gaia1 = gaia1_row['dec']\n",
    "        parallax_gaia1 = gaia1_row['parallax']  # Extract parallax from gaia\n",
    "        \n",
    "        # Check if the difference between RA and DEC values is within tolerance\n",
    "        ra_diff = abs(ra_south - ra_gaia1)\n",
    "        dec_diff = abs(dec_south - dec_gaia1)\n",
    "        \n",
    "        if ra_diff <= tolerance and dec_diff <= tolerance:\n",
    "            # If within tolerance, set the parallax value\n",
    "            parallax_value = parallax_gaia1\n",
    "            # Break the loop as we found a match for the current df_south_degrees row\n",
    "            break\n",
    "    \n",
    "    # If parallax value is not None, add the row to Southdf\n",
    "    if parallax_value is not None:\n",
    "        Southdf = Southdf.append({'R.A. (J2000)': ra_south, 'Decl. (J2000)': dec_south, 'parallax': parallax_value}, ignore_index=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(Southdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c472832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the distances function\n",
    "def calculate_distance(parallax):\n",
    "    return (1/(abs(parallax)*10**-3))\n",
    "\n",
    "# Calculate distances for each parallax value in filtered_C1df\n",
    "distance = calculate_distance(Southdf['parallax'])\n",
    "\n",
    "# Add distances to the filtered_C1df DataFrame\n",
    "Southdf['distance'] = distance\n",
    "\n",
    "# Remove rows where the calculated distance exceeds 1500 parsecs\n",
    "SouthdfS = Southdf[Southdf['distance'] <= 1900]\n",
    "\n",
    "print(SouthdfS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the distances function\n",
    "def calculate_distances(parallax):\n",
    "    return (1/(abs(parallax)*10**-3))\n",
    "\n",
    "# Calculate distances for each parallax value in filtered_C1df\n",
    "distance = calculate_distances(filtered_C1df['parallax'])\n",
    "\n",
    "# Add distances to the filtered_C1df DataFrame\n",
    "filtered_C1df['distance'] = distance\n",
    "\n",
    "# Remove rows where the calculated distance exceeds 1500 parsecs\n",
    "NorthC1df = filtered_C1df[filtered_C1df['distance'] <= 1900]\n",
    "\n",
    "print(NorthC1df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram for filtered_C1df\n",
    "plt.hist(filtered_C1df['distance'], bins=20, color='skyblue', edgecolor='black', label='Northern Cluster Data')\n",
    "\n",
    "plt.hist(SouthdfS['distance'], bins=20, color='blue', edgecolor='black', label='Southern Cluster Data')\n",
    "\n",
    "\n",
    "plt.hist(distances, bins=80, range=(0, 2000), alpha=0.5, label='Distances from Gaia Northern')\n",
    "\n",
    "plt.hist(distances2, bins=80, range=(0, 2000), alpha=0.5, label='Distances from Gaia Southern')\n",
    "\n",
    "\n",
    "plt.title('Distance Distribution')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('distance_distributionTOTAL.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa10b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plotting the first histogram for northern data with Gaia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(filtered_C1df['distance'], bins=20, color='skyblue', edgecolor='black', label='Northern Cluster Data with Gaia')\n",
    "plt.hist(distances, bins=80, range=(0, 2000), alpha=0.5, label='Distances from Gaia Northern')\n",
    "plt.title('Northern Cluster Data')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the second histogram for southern data with Gaia1\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(SouthdfS['distance'], bins=20, color='skyblue', edgecolor='black', label='Southern Cluster Data with Gaia1')\n",
    "plt.hist(distances2, bins=80, range=(0, 2000), alpha=0.5, label='Distances from Gaia1 Southern')\n",
    "plt.title('Southern Cluster Data')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig('distance_distributionSEP.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#USE CONCENTRATED AREAS (MIDDLE) FOR RADIAL DENSITY PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac12e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#NEW\n",
    "#\n",
    "#\n",
    "\n",
    "C1df_2mass = pd.read_excel(\"C1df_2mass.xlsx\")\n",
    "\n",
    "matchedNORTH_df = pd.merge(NorthC1df, C1df_2mass, on=['RA', 'DEC'], how='inner')\n",
    "\n",
    "# Optionally, save the matched dataframe to a new file\n",
    "matchedNORTH_df.to_csv('matchedNORTH_df.csv', index=False)\n",
    "\n",
    "# Display the matched dataframe\n",
    "print(matchedNORTH_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61abf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# #\n",
    "# #\n",
    "# #NEW\n",
    "# #\n",
    "# #\n",
    "\n",
    "# C1df_2mass = pd.read_excel(\"C1df_2mass.xlsx\")\n",
    "\n",
    "# matchedNORTH_df = pd.merge(NorthC1df, C1df_2mass, on=['RA', 'DEC'], how='inner')\n",
    "\n",
    "# # Optionally, save the matched dataframe to a new file\n",
    "# matchedNORTH_df.to_csv('matchedNORTH_df.csv', index=False)\n",
    "\n",
    "# # Display the matched dataframe\n",
    "# print(matchedNORTH_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(parallax):\n",
    "    return (1/(abs(parallax)*10**-3))\n",
    "\n",
    "# Calculate distances for each parallax value in filtered_C1df\n",
    "distance = calculate_distance(C1df_2mass['parallax'])\n",
    "\n",
    "# Add distances to the filtered_C1df DataFrame\n",
    "C1df_2mass['distance'] = distance\n",
    "\n",
    "# Remove rows where the calculated distance exceeds 1500 parsecs\n",
    "C1Df_2mass = C1df_2mass[C1df_2mass['distance'] <= 1900]\n",
    "\n",
    "print(C1Df_2mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#NEW\n",
    "\n",
    "# Define the function to calculate distance from parallax\n",
    "def calculate_distance(parallax):\n",
    "    return 1 / (abs(parallax) * 10**-3)\n",
    "\n",
    "\n",
    "SOUTH_df['distance'] = SOUTH_df['parallax'].apply(calculate_distance)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(SOUTH_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = 1000\n",
    "\n",
    "# Filter the data to exclude extreme outliers\n",
    "filtered_south_df = SOUTH_df[SOUTH_df['distance'] < distance_threshold]\n",
    "\n",
    "print(filtered_south_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plotting the first histogram for northern data with Gaia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(C1Df_2mass['distance'], bins=15, color='black', alpha=0.5, label='Infrared Sources (Northern)', edgecolor='black')\n",
    "plt.hist(NorthC1df['distance'], bins=15, histtype='step', linestyle=':', linewidth=1.5, color='blue', label='Northern Cluster Data with Gaia')\n",
    "\n",
    "plt.title('Northern Cluster Data')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "#\n",
    "\n",
    "# Plotting the second histogram for southern data with Gaia1\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(filtered_south_df['distance'], bins=15, color='black',alpha=0.5, label='Infrared Sources (Southern)')\n",
    "plt.hist(SouthdfS['distance'], bins=15,  histtype='step', linestyle=':', linewidth=1.5, color='blue', label='Southern Cluster Data with Gaia')\n",
    "\n",
    "plt.title('Southern Cluster Data')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig('IR_V_distance_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Southern Data (Infrared):\", SOUTH_df['distance'].describe())\n",
    "print(\"Southern Data (Gaia):\", SouthdfS['distance'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73692351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(filtered_C1df['distance'], bins=40, range=(700, 800), color='skyblue', edgecolor='black', label='Northern Cluster Data with Gaia')\n",
    "plt.hist(distances, bins=40, range=(700, 800), alpha=0.25, label='Distances from Gaia Northern')\n",
    "plt.title('Northern Cluster Data (Condensed)')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(filtered_C1df['distance'], bins=40, range=(300, 500), color='skyblue', edgecolor='black', label='Northern Cluster Data with Gaia')\n",
    "plt.hist(distances, bins=40, range=(300, 500), alpha=0.25, label='Distances from Gaia Northern')\n",
    "plt.title('Northern Cluster Data (Condensed)')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14bfcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(SouthdfS['distance'], bins=40, range=(700, 800), color='skyblue', edgecolor='black', label='Southern Cluster Data with Gaia')\n",
    "plt.hist(distances2, bins=40, range=(700, 800), alpha=0.25, label='Distances from Gaia Southern')\n",
    "plt.title('Southern Cluster Data (Condensed)')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(SouthdfS['distance'], bins=20, range=(250, 500), color='skyblue', edgecolor='black', label='Southern Cluster Data with Gaia')\n",
    "plt.hist(distances2, bins=20, range=(250, 500), alpha=0.25, label='Distances from Gaia Southern')\n",
    "plt.title('Southern Cluster Data (Condensed)')\n",
    "plt.xlabel('Distance (parsecs)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b245e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Given Data\n",
    "mainsequence_j_k_koornneef83 = np.array([-0.21, -0.19, -0.18, -0.17, -0.15, -0.14, -0.13, -0.11, -0.1, -0.08, -0.07, -0.05, -0.04, -0.02, 0.01, 0.02, 0.04, 0.05, 0.07, 0.09, 0.1, 0.12, 0.14, 0.17, 0.2, 0.24, 0.26, 0.29, 0.31, 0.37, 0.41, 0.47, 0.54, 0.62, 0.67, 0.72, 0.77, 0.83, 0.86, 0.89, 0.92, 0.9, 0.9, 0.88, 0.89, 0.9, 0.92, 0.95, 0.98, 1.01, 1.05, 1.09, 1.11, 1.14])\n",
    "mainsequence_h_k_koornneef83 = np.array([-0.05, -0.05, -0.05, -0.05, -0.04, -0.04, -0.04, -0.03, -0.03, -0.02, -0.02, -0.02, -0.01, -0.01, 0, 0, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.03, 0.04, 0.04, 0.05, 0.06, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.13, 0.14, 0.15, 0.16, 0.18, 0.19, 0.21, 0.26, 0.28, 0.29, 0.3, 0.31, 0.33, 0.34, 0.36, 0.37, 0.38, 0.4, 0.41, 0.42, 0.43])\n",
    "mainsequence_j_h_koornneef83 = [mainsequence_j_k_koornneef83[i] - mainsequence_h_k_koornneef83[i] for i in range(54)]\n",
    "mainsequence_k_koornneef83 = [mainsequence_j_k_koornneef83[i] - mainsequence_h_k_koornneef83[i] for i in range(54)]\n",
    "giant_j_k_koornneef83 = np.array([0.56, 0.59, 0.64, 0.68, 0.72, 0.8, 0.88, 0.96, 0.97, 1.01, 1.04, 1.1, 1.16, 1.24, 1.3])\n",
    "giant_h_k_koornneef83 = np.array([0.11, 0.12, 0.13, 0.14, 0.14, 0.16, 0.18, 0.2, 0.21, 0.21, 0.23, 0.25, 0.27, 0.31, 0.35])\n",
    "giant_j_h_koornneef83 = [giant_j_k_koornneef83[i] - giant_h_k_koornneef83[i] for i in range(len(giant_j_k_koornneef83))]\n",
    "\n",
    "# Transformations from Carpenter 2001\n",
    "mainsequence_j_k_2mass = [((0.970 * i) - 0.017) for i in mainsequence_j_k_koornneef83]\n",
    "mainsequence_h_k_2mass = [((0.792 * i) + 0.027) for i in mainsequence_h_k_koornneef83]\n",
    "mainsequence_j_h_2mass = [((1.024 * i) - 0.045) for i in mainsequence_j_h_koornneef83]\n",
    "mainsequence_k_2mass = [(mainsequence_k_koornneef83[i] + (0.039 * mainsequence_j_k_2mass[i]) - 0.047) for i in range(0, len(mainsequence_k_koornneef83))]\n",
    "giant_j_k_2mass = [((0.970 * i) - 0.017) for i in giant_j_k_koornneef83]\n",
    "giant_h_k_2mass = [((0.792 * i) + 0.027) for i in giant_h_k_koornneef83]\n",
    "giant_j_h_2mass = [((1.024 * i) - 0.045) for i in giant_j_h_koornneef83]\n",
    "\n",
    "# Fit a 10th-degree polynomial to the data for the main sequence stars\n",
    "x = mainsequence_h_k_2mass\n",
    "y = mainsequence_j_h_2mass\n",
    "z = np.polyfit(x, y, 10)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "# Create interpolated values using the polynomial fit\n",
    "mainsequence_h_k = np.linspace(x[0], x[-1], 50)\n",
    "mainsequence_j_h = f(mainsequence_h_k)\n",
    "\n",
    "# Convert magnitudes to flux\n",
    "jzp = 1594.0 * 10**6\n",
    "hzp = 1024.0 * 10**6\n",
    "kzp = 666.7 * 10**6\n",
    "\n",
    "# Extinction coefficients\n",
    "A_V = 1.0  # arbitrary value, the ratio is what's important\n",
    "A_J = 0.282 * A_V\n",
    "A_H = 0.175 * A_V\n",
    "A_K = 0.112 * A_V\n",
    "\n",
    "# Reddening vector slopes\n",
    "E_J_H = A_J - A_H\n",
    "E_H_K = A_H - A_K\n",
    "reddening_slope = E_J_H / E_H_K\n",
    "\n",
    "# Define reddening vectors\n",
    "vector_length = 0.8  # arbitrary length for the vector\n",
    "\n",
    "start_giant = None\n",
    "for h_k, j_h in zip(giant_h_k_2mass, giant_j_h_2mass):\n",
    "    if 0.2 <= h_k <= 0.3 and 0.85 <= j_h <= 0.9:\n",
    "        start_giant = (h_k, j_h)\n",
    "        break\n",
    "\n",
    "# Find the starting point for the main sequence within the specified range\n",
    "start_mainsequence = None\n",
    "for h_k, j_h in zip(mainsequence_h_k, mainsequence_j_h):\n",
    "    if 0.0 <= h_k <= 0.1 and 0.1 <= j_h <= 0.2:\n",
    "        start_mainsequence = (h_k, j_h)\n",
    "        break\n",
    "\n",
    "if start_giant:\n",
    "    end_giant = (start_giant[0] + vector_length, start_giant[1] + vector_length * reddening_slope)\n",
    "else:\n",
    "    end_giant = None\n",
    "\n",
    "if start_mainsequence:\n",
    "    end_mainsequence = (start_mainsequence[0] + vector_length, start_mainsequence[1] + vector_length * reddening_slope)\n",
    "else:\n",
    "    end_mainsequence = None\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(giant_h_k_2mass, giant_j_h_2mass, color='black', linestyle='--', label=\"Giant\")\n",
    "plt.plot(mainsequence_h_k, mainsequence_j_h, color='black', label=\"Main Sequence\", linestyle='-')  # Main sequence data as a line plot\n",
    "plt.scatter(JHK_df['H_K'], JHK_df['J_H'], color='black', label=\"North Cluster\", marker='o', s=5)  # Assuming JHK_df is defined elsewhere\n",
    "\n",
    "if start_giant and end_giant:\n",
    "    plt.arrow(start_giant[0], start_giant[1], end_giant[0] - start_giant[0], end_giant[1] - start_giant[1],\n",
    "              color='black', linestyle=':', label=\"Reddening Vector (Giant)\")\n",
    "\n",
    "if start_mainsequence and end_mainsequence:\n",
    "    plt.arrow(start_mainsequence[0], start_mainsequence[1], end_mainsequence[0] - start_mainsequence[0], end_mainsequence[1] - start_mainsequence[1],\n",
    "              color='black', linestyle=':', label=\"Reddening Vector (Main Sequence)\")\n",
    "\n",
    "plt.xlabel('H-K')\n",
    "plt.ylabel('J-H')\n",
    "plt.legend()\n",
    "plt.title('Color-Color Diagram')\n",
    "plt.savefig('Color-Color Diagram (North)', dpi=100, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#NORTH!!!\n",
    "\n",
    "# Assume NorthC1df['RA'] and NorthC1df['DEC'] are in degrees\n",
    "x = NorthC1df['RA'].values\n",
    "y = NorthC1df['DEC'].values\n",
    "\n",
    "# Cluster center coordinates (replace with your actual cluster center)\n",
    "cluster_center = (100.26, 9.885)\n",
    "\n",
    "# Convert coordinates to arcseconds\n",
    "x_arcsec = np.array((x - cluster_center[0]) * 3600, dtype=np.float64)\n",
    "y_arcsec = np.array((y - cluster_center[1]) * 3600, dtype=np.float64)\n",
    "\n",
    "# Compute distances from cluster center in arcseconds\n",
    "distances_arcsec = np.sqrt(x_arcsec**2 + y_arcsec**2)\n",
    "\n",
    "distance_to_cluster_pc = 760 \n",
    "arcsec_to_pc_conversion_factor = distance_to_cluster_pc / 206265\n",
    "distances_pc = distances_arcsec * arcsec_to_pc_conversion_factor\n",
    "\n",
    "# Define concentric rings with increasing radii (in parsecs)\n",
    "radius_bins = np.arange(0, np.ceil(np.max(distances)) + 20, 20)  # 20 arcsecond bins\n",
    "\n",
    "# Initialize arrays to store surface density values\n",
    "surface_density = np.zeros(len(radius_bins) - 1)\n",
    "\n",
    "for i in range(len(radius_bins) - 1):  # Iterate over each bin except the last one\n",
    "    # Find stars within the current ring\n",
    "    stars_in_ring = (distances_pc >= radius_bins[i]) & (distances_pc < radius_bins[i + 1])\n",
    "    \n",
    "    # Count the number of stars in the current ring\n",
    "    num_stars_in_ring = np.sum(stars_in_ring)\n",
    "\n",
    "    # Compute the area of the current ring in square parsecs\n",
    "    ring_area = np.pi * ((radius_bins[i + 1])**2 - (radius_bins[i])**2)\n",
    "\n",
    "    # Compute surface density: number of stars per square parsec\n",
    "    if ring_area > 0:\n",
    "        surface_density[i] = num_stars_in_ring / ring_area\n",
    "    else:\n",
    "        surface_density[i] = 0 \n",
    "        \n",
    "\n",
    "def power_law(radius, a, b):\n",
    "    return a * radius ** b\n",
    "\n",
    "# Fit the power law to the data\n",
    "# Avoid zero radius by taking the average of bin edges and making sure none is zero\n",
    "bin_centers = (radius_bins[:-1] + radius_bins[1:]) / 2\n",
    "non_zero_indices = bin_centers > 0  # Remove zero or negative values\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(\n",
    "        power_law,\n",
    "        bin_centers[non_zero_indices],\n",
    "        surface_density[non_zero_indices],\n",
    "        p0=initial_guess,\n",
    "        maxfev=2000 \n",
    "    )\n",
    "\n",
    "# Debugging: Print optimized parameters\n",
    "print(\"Optimized Parameters (a, b):\", popt)\n",
    "\n",
    "# Generate the power law curve using the optimized parameters\n",
    "# Start the radius_fit from a small positive number to avoid zero\n",
    "radius_fit = np.linspace(max(min(radius_bins), 1e-5), max(radius_bins), 100)\n",
    "surface_density_fit = power_law(radius_fit, *popt)\n",
    "\n",
    "# Plot the surface density profile and the fitted power law\n",
    "plt.scatter((radius_bins[:-1] + radius_bins[1:]) / 2, surface_density, label='Data')\n",
    "plt.plot(radius_fit, surface_density_fit, color='red', label='Power Law Fit')\n",
    "plt.xlabel('Radius from Cluster Center (parsecs)')\n",
    "plt.ylabel('Surface Density (stars per square parsec)')\n",
    "plt.title('Radial Surface Density Profile with Power Law Fit')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Customize the y-axis range to go by increments of 10\n",
    "plt.yticks(np.arange(0, max(surface_density) + 10, 10))\n",
    "plt.savefig('radialsurfacedensity1.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Sample star positions (replace with your actual data)\n",
    "x = gaia['ra'].values\n",
    "y = gaia['dec'].values\n",
    "\n",
    "# Cluster center coordinates (replace with your actual cluster center)\n",
    "cluster_center = (100.26, 9.885)\n",
    "\n",
    "# Convert coordinates to arcseconds\n",
    "x_arcsec = (x - cluster_center[0]) * 3600\n",
    "y_arcsec = (y - cluster_center[1]) * 3600\n",
    "\n",
    "# Compute distances from cluster center\n",
    "distances = np.sqrt(x_arcsec**2 + y_arcsec**2)\n",
    "\n",
    "# Define concentric rings with increasing radii (in arcseconds)\n",
    "radius_bins = np.arange(0, np.ceil(np.max(distances)) + 1, 20)  # 20 arcsecond bins\n",
    "\n",
    "# Initialize arrays to store surface density values\n",
    "surface_density = np.zeros(len(radius_bins) - 1)\n",
    "\n",
    "# Count stars within each ring and compute surface density\n",
    "for i in range(len(surface_density)):\n",
    "    stars_in_ring = (distances >= radius_bins[i]) & (distances < radius_bins[i+1])\n",
    "    num_stars_in_ring = np.sum(stars_in_ring)\n",
    "    ring_area = np.pi * ((radius_bins[i+1])**2 - (radius_bins[i])**2)\n",
    "    surface_density[i] = num_stars_in_ring / ring_area if num_stars_in_ring > 0 else 0\n",
    "\n",
    "# Convert surface density from stars per square arcsecond to stars per square arcminute\n",
    "surface_density_arcmin = surface_density / 3600\n",
    "\n",
    "# Fit the power law to the data\n",
    "def power_law(radius, a, b):\n",
    "    return a * radius ** b\n",
    "\n",
    "popt, pcov = curve_fit(power_law, (radius_bins[:-1] + radius_bins[1:]) / 2, surface_density_arcmin)\n",
    "\n",
    "# Generate the power law curve using the optimized parameters\n",
    "radius_fit = np.linspace(min(radius_bins), max(radius_bins), 100)\n",
    "surface_density_fit_arcmin = power_law(radius_fit, *popt)\n",
    "\n",
    "# Plot the surface density profile and the fitted power law\n",
    "plt.scatter((radius_bins[:-1] + radius_bins[1:]) / 2, surface_density_arcmin, label='Data', color='black')\n",
    "plt.plot(radius_fit, surface_density_fit_arcmin, color='black', label='Power Law Fit')\n",
    "plt.xlabel('Radius from Cluster Center (arcseconds)')\n",
    "plt.ylabel('Surface Density (stars per square arcminute)')\n",
    "plt.title('Radial Surface Density Profile with Power Law Fit')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('radialsurfacedensity2.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac869264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied\n",
    "# mainsequence_j_k_koornneef83 = np.array([-0.21, -0.19, -0.18, -0.17, -0.15, -0.14, -0.13, -0.11, -0.1, -0.08, -0.07, -0.05, -0.04, -0.02, 0.01, 0.02, 0.04, 0.05, 0.07, 0.09, 0.1, 0.12, 0.14, 0.17, 0.2, 0.24, 0.26, 0.29, 0.31, 0.37, 0.41, 0.47, 0.54, 0.62, 0.67, 0.72, 0.77, 0.83, 0.86, 0.89, 0.92, 0.9, 0.9, 0.88, 0.89, 0.9, 0.92, 0.95, 0.98, 1.01, 1.05, 1.09, 1.11, 1.14])\n",
    "# mainsequence_h_k_koornneef83 = np.array([-0.05, -0.05, -0.05, -0.05, -0.04, -0.04, -0.04, -0.03, -0.03, -0.02, -0.02, -0.02, -0.01, -0.01, 0, 0, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.03, 0.04, 0.04, 0.05, 0.06, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.13, 0.14, 0.15, 0.16, 0.18, 0.19, 0.21, 0.26, 0.28, 0.29, 0.3, 0.31, 0.33, 0.34, 0.36, 0.37, 0.38, 0.4, 0.41, 0.42, 0.43])\n",
    "# mainsequence_j_h_koornneef83 = [mainsequence_j_k_koornneef83[i] - mainsequence_h_k_koornneef83[i] for i in range(54)]\n",
    "# mainsequence_k_koornneef83 = [mainsequence_j_k_koornneef83[i] - mainsequence_h_k_koornneef83[i] for i in range(54)]\n",
    "# giant_j_k_koornneef83 = np.array([0.56, 0.59, 0.64, 0.68, 0.72, 0.8, 0.88, 0.96, 0.97, 1.01, 1.04, 1.1, 1.16, 1.24, 1.3])\n",
    "# giant_h_k_koornneef83 = np.array([0.11, 0.12, 0.13, 0.14, 0.14, 0.16, 0.18, 0.2, 0.21, 0.21, 0.23, 0.25, 0.27, 0.31, 0.35])\n",
    "# giant_j_h_koornneef83 = [giant_j_k_koornneef83[i] - giant_h_k_koornneef83[i] for i in range(len(giant_j_k_koornneef83))]\n",
    "\n",
    "# # Transformations from Carpenter 2001\n",
    "# mainsequence_j_k_2mass = [((0.970 * i) - 0.017) for i in mainsequence_j_k_koornneef83]\n",
    "# mainsequence_h_k_2mass = [((0.792 * i) + 0.027) for i in mainsequence_h_k_koornneef83]\n",
    "# mainsequence_j_h_2mass = [((1.024 * i) - 0.045) for i in mainsequence_j_h_koornneef83]\n",
    "# mainsequence_k_2mass = [(mainsequence_k_koornneef83[i] + (0.039 * mainsequence_j_k_2mass[i]) - 0.047) for i in range(0, len(mainsequence_k_koornneef83))]\n",
    "# giant_j_k_2mass = [((0.970 * i) - 0.017) for i in giant_j_k_koornneef83]\n",
    "# giant_h_k_2mass = [((0.792 * i) + 0.027) for i in giant_h_k_koornneef83]\n",
    "# giant_j_h_2mass = [((1.024 * i) - 0.045) for i in giant_j_h_koornneef83]\n",
    "\n",
    "# # Fit a 10th-degree polynomial to the data for the main sequence stars\n",
    "# x = mainsequence_h_k_2mass\n",
    "# y = mainsequence_j_h_2mass\n",
    "# z = np.polyfit(x, y, 10)\n",
    "# f = np.poly1d(z)\n",
    "\n",
    "# # Create interpolated values using the polynomial fit\n",
    "# mainsequence_h_k = np.linspace(x[0], x[-1], 50)\n",
    "# mainsequence_j_h = f(mainsequence_h_k)\n",
    "\n",
    "# # Convert magnitudes to flux\n",
    "# jzp = 1594.0 * 10**6\n",
    "# hzp = 1024.0 * 10**6\n",
    "# kzp = 666.7 * 10**6\n",
    "\n",
    "# #To incorporate the reddening lines into your color-color diagram, \n",
    "# #you need to determine the slopes of the reddening vectors in the J-H nad H-K\n",
    "# #pace. These slopes are usually determined based on the extinction law, which gives \n",
    "# #the ratio of extinctions in different bands.\n",
    "\n",
    "# # Extinction coefficients\n",
    "# A_V = 1.0  # arbitrary value, the ratio is what's important\n",
    "# A_J = 0.282 * A_V\n",
    "# A_H = 0.175 * A_V\n",
    "# A_K = 0.112 * A_V\n",
    "\n",
    "# # Reddening vector slopes\n",
    "# E_J_H = A_J - A_H\n",
    "# E_H_K = A_H - A_K\n",
    "# reddening_slope = E_J_H / E_H_K\n",
    "\n",
    "# # Define reddening vectors\n",
    "# vector_length = 0.8  # arbitrary length for the vector\n",
    "\n",
    "# start_giant = None\n",
    "# for h_k, j_h in zip(giant_h_k_2mass, giant_j_h_2mass):\n",
    "#     if 0.2 <= h_k <= 0.3 and 0.85 <= j_h <= 0.9:\n",
    "#         start_giant = (h_k, j_h)\n",
    "#         break\n",
    "\n",
    "# # Find the starting point for the blue line (main sequence)\n",
    "# start_mainsequence = (mainsequence_h_k[0], mainsequence_j_h[0])\n",
    "\n",
    "# if start_giant:\n",
    "#     end_giant = (start_giant[0] + vector_length, start_giant[1] + vector_length * reddening_slope)\n",
    "# else:\n",
    "#     end_giant = None\n",
    "\n",
    "\n",
    "# end_mainsequence = (start_mainsequence[0] + vector_length, start_mainsequence[1] + vector_length * reddening_slope)\n",
    "\n",
    "        \n",
    "# plt.figure(figsize=(7, 7))\n",
    "# plt.plot(giant_h_k_2mass, giant_j_h_2mass, color='black', linestyle='--', label=\"Giant\")\n",
    "# plt.plot(mainsequence_h_k, mainsequence_j_h, color='black', label=\"Main Sequence\", linestyle='-')  # Main sequence data as a line plot\n",
    "# plt.scatter(JHK_df['H_K'], JHK_df['J_H'], color='black', label=\"North Cluster\", marker='o', s=5) \n",
    "\n",
    "# if start_giant and end_giant:\n",
    "#     plt.arrow(start_giant[0], start_giant[1], end_giant[0] - start_giant[0], end_giant[1] - start_giant[1],\n",
    "#               color='black', linestyle=':', label=\"Reddening Vector (Giant)\")\n",
    "\n",
    "# plt.arrow(start_mainsequence[0], start_mainsequence[1], end_mainsequence[0] - start_mainsequence[0], end_mainsequence[1] - start_mainsequence[1],\n",
    "#           color='black', linestyle=':',label=\"Reddening Vector (Main Sequence)\")\n",
    "\n",
    "# plt.xlabel('H-K')\n",
    "# plt.ylabel('J-H')\n",
    "# plt.legend()\n",
    "# plt.title('Color-Color Diagram')\n",
    "# plt.savefig('Color-Color Diagram (North)', dpi=100, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
